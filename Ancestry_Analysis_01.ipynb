{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roaring60s/ancestry_analysis/blob/main/Ancestry_Analysis_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a bioinformatician and anthropologist, I've developed a pure Python script to provide a simplified, illustrative modern ethnic admixture analysis, similar in concept to commercial DNA tests.\n",
        "\n",
        "This code estimates an individual's ancestry proportions based on their genotype data and a reference panel of ethnic allele frequencies. It's important to understand that this is a simplified model. Professional tools use complex statistical algorithms and vast, proprietary datasets. This script, however, serves as a great educational tool to understand the core principles.\n",
        "\n",
        "Due to the **no external libraries** constraint, the script manually parses input files and uses text-based characters with ANSI color codes to generate a stacked bar chart directly in your terminal. It relies only on Python's standard library, particularly the `math` module for calculations.\n",
        "\n",
        "### The Scientific Approach\n",
        "\n",
        "The script operates on a fundamental principle of population genetics: different populations have different frequencies of specific genetic variants. The analysis follows these steps:\n",
        "\n",
        "1.  **Data Parsing**: It reads your genetic data from a VCF (Variant Call Format) file and the reference data from a TSV (Tab-Separated Values) file.\n",
        "2.  **Population Grouping**: Real-world reference panels can have dozens or hundreds of populations. For a clearer overview, the script aggregates the 79 reference ethnicities into 10 major continental groups. I've created a sample mapping for this purpose.\n",
        "3.  **Likelihood Calculation**: For each major population, the script calculates the total likelihood of observing your specific genotypes. This is done by multiplying the probabilities of your genotype at each of the 100 variants, assuming Hardy-Weinberg Equilibrium. To handle the very small numbers involved, it computes the sum of log-likelihoods.\n",
        "4.  **Normalization**: The calculated likelihood scores are normalized to sum to 100%. These final values are the estimated percentage contributions from each major population group to your genome.\n",
        "5.  **Visualization**: The results are displayed as a single, colored, stacked bar chart in the terminal, with a legend detailing the contribution of each ancestral group.\n",
        "\n",
        "-----\n",
        "\n",
        "### Python Code for Ethnic Admixture Estimation\n",
        "\n",
        "Here is the complete, self-contained Python script. You can run it as-is to see an example, then replace the contents of `sample_vcf_data` and `reference_tsv_data` with your actual file data."
      ],
      "metadata": {
        "id": "0jHPlhrmx25_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import sys\n",
        "\n",
        "# --- CONFIGURATION & DATA MAPPING ---\n",
        "\n",
        "# A mapping from 79 illustrative ethnicities in the reference file to 10 major population groups.\n",
        "# This is a crucial anthropological step and should be curated based on the actual reference panel.\n",
        "POPULATION_MAP = {\n",
        "    # African\n",
        "    'Yoruba': 'African', 'Mende': 'African', 'Luhya': 'African', 'Gambian': 'African', 'Esan': 'African',\n",
        "    # Middle Eastern\n",
        "    'Bedouin': 'Middle Eastern', 'Egyptian': 'Middle Eastern', 'Druze': 'Middle Eastern', 'Palestinian': 'Middle Eastern', 'Mozabite': 'Middle Eastern',\n",
        "    # European\n",
        "    'British': 'European', 'Finnish': 'European', 'Spanish': 'European', 'Tuscan': 'European', 'French': 'European', 'Russian': 'European', 'Sardinian': 'European',\n",
        "    # Central/South Asian\n",
        "    'Punjabi': 'Central/South Asian', 'Gujarati': 'Central/South Asian', 'Bengali': 'Central/South Asian', 'Telugu': 'Central/South Asian', 'Tamil': 'Central/South Asian',\n",
        "    # East Asian\n",
        "    'HanChinese': 'East Asian', 'Japanese': 'East Asian', 'Korean': 'East Asian', 'Vietnamese': 'East Asian', 'Dai': 'East Asian',\n",
        "    # Americas\n",
        "    'Peruvian': 'Americas', 'Colombian': 'Americas', 'Mayan': 'Americas', 'Pima': 'Americas', 'Karitiana': 'Americas',\n",
        "    # Oceanian\n",
        "    'Papuan': 'Oceanian', 'Melanesian': 'Oceanian', 'Australian': 'Oceanian',\n",
        "    # Added more for the 79 total count\n",
        "    'Italian': 'European', 'Orcadian': 'European', 'Adygei': 'Middle Eastern', 'Basque': 'European', 'Bantu': 'African', 'San': 'African', 'MbutiPygmy': 'African',\n",
        "    'BiakaPygmy': 'African', 'Uygur': 'Central/South Asian', 'Hazara': 'Central/South Asian', 'Kalash': 'Central/South Asian', 'Pathan': 'Central/South Asian',\n",
        "    'Burusho': 'Central/South Asian', 'Makrani': 'Central/South Asian', 'Sindhi': 'Central/South Asian', 'Brahui': 'Central/South Asian',\n",
        "    'Balochi': 'Central/South Asian', 'Yakut': 'East Asian', 'Mongola': 'East Asian', 'Daur': 'East Asian', 'Hezhen': 'East Asian', 'Xibo': 'East Asian',\n",
        "\n",
        "    # Remainder to fill 79 ethnicities (illustrative)\n",
        "    'Naxi': 'East Asian', 'Yi': 'East Asian', 'Tu': 'East Asian', 'Tujia': 'East Asian', 'She': 'East Asian',\n",
        "    'Miao': 'East Asian', 'Lahu': 'East Asian', 'Cambodian': 'East Asian', 'Surui': 'Americas', 'Quechua': 'Americas',\n",
        "    'Mixtec': 'Americas', 'Zapotec': 'Americas', 'Mixe': 'Americas', 'Tlingit': 'Americas', 'Inuit': 'Americas',\n",
        "    'Chukchi': 'East Asian', 'Koryak': 'East Asian', 'Itelmen': 'East Asian', 'Evenk': 'East Asian', 'Nanai': 'East Asian',\n",
        "    'Ulchi': 'East Asian', 'Negidal': 'East Asian', 'Oroqen': 'East Asian', 'Ewen': 'East Asian', 'Dolgans': 'East Asian',\n",
        "    'Nganasan': 'East Asian', 'Enets': 'East Asian', 'Selkup': 'East Asian', 'Ket': 'Central/South Asian', 'Samoyed': 'European'\n",
        "}\n",
        "\n",
        "\n",
        "# --- EXAMPLE INPUT DATA ---\n",
        "# In a real scenario, you would read this from files.\n",
        "# For this example, data is stored in multiline strings.\n",
        "\n",
        "# Example VCF data for a single sample with 5 variants\n",
        "sample_vcf_data = \"\"\"##fileformat=VCFv4.2\n",
        "##INFO=<ID=NS,Number=1,Type=Integer,Description=\"Number of Samples With Data\">\n",
        "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE_01\n",
        "chr1\t1001\trs1\tA\tG\t100\tPASS\t.\tGT\t0/1\n",
        "chr1\t2002\trs2\tC\tT\t100\tPASS\t.\tGT\t1/1\n",
        "chr2\t3003\trs3\tG\tA\t100\tPASS\t.\tGT\t0/0\n",
        "chr5\t4004\trs4\tT\tC\t100\tPASS\t.\tGT\t1/1\n",
        "chr7\t5005\trs5\tC\tG\t100\tPASS\t.\tGT\t0/1\n",
        "\"\"\"\n",
        "\n",
        "# Example reference allele frequencies for 5 variants across 6 ethnicities\n",
        "# NOTE: A real file would have 100 variants and 79 ethnicities\n",
        "reference_tsv_data = \"\"\"VariantID\tBritish\tFrench\tYoruba\tMende\tHanChinese\tJapanese\n",
        "rs1\t0.51\t0.48\t0.95\t0.92\t0.05\t0.03\n",
        "rs2\t0.20\t0.22\t0.01\t0.02\t0.85\t0.89\n",
        "rs3\t0.88\t0.85\t0.15\t0.18\t0.30\t0.33\n",
        "rs4\t0.05\t0.07\t0.65\t0.68\t0.95\t0.92\n",
        "rs5\t0.40\t0.42\t0.80\t0.77\t0.10\t0.12\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# --- CORE LOGIC ---\n",
        "\n",
        "def parse_vcf(vcf_content):\n",
        "    \"\"\"\n",
        "    Parses VCF data to extract sample genotypes.\n",
        "    Genotypes are coded as: 0 (homozygous reference), 1 (heterozygous), 2 (homozygous alternate).\n",
        "    \"\"\"\n",
        "    sample_genotypes = {}\n",
        "    lines = vcf_content.strip().split('\\\\n')\n",
        "    for line in lines:\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        fields = line.split('\\\\t')\n",
        "        variant_id = fields[2]\n",
        "        genotype_str = fields[9].split(':')[0]\n",
        "\n",
        "        if genotype_str == '0/0' or genotype_str == '0|0':\n",
        "            sample_genotypes[variant_id] = 0\n",
        "        elif genotype_str == '0/1' or genotype_str == '0|1' or genotype_str == '1|0':\n",
        "            sample_genotypes[variant_id] = 1\n",
        "        elif genotype_str == '1/1' or genotype_str == '1|1':\n",
        "            sample_genotypes[variant_id] = 2\n",
        "    return sample_genotypes\n",
        "\n",
        "\n",
        "def parse_reference(tsv_content):\n",
        "    \"\"\"\n",
        "    Parses the reference TSV file of allele frequencies.\n",
        "    Returns a dictionary: {variant_id: {ethnicity: frequency}}\n",
        "    \"\"\"\n",
        "    reference_freqs = {}\n",
        "    lines = tsv_content.strip().split('\\\\n')\n",
        "    header = lines[0].split('\\\\t')\n",
        "    ethnicities = header[1:]\n",
        "\n",
        "    for line in lines[1:]:\n",
        "        fields = line.split('\\\\t')\n",
        "        variant_id = fields[0]\n",
        "        reference_freqs[variant_id] = {}\n",
        "        for i, freq_str in enumerate(fields[1:]):\n",
        "            ethnicity = ethnicities[i]\n",
        "            # Handle potential conversion errors or empty strings\n",
        "            try:\n",
        "                reference_freqs[variant_id][ethnicity] = float(freq_str)\n",
        "            except ValueError:\n",
        "                reference_freqs[variant_id][ethnicity] = 0.0 # Assign a neutral frequency\n",
        "\n",
        "    return reference_freqs\n",
        "\n",
        "\n",
        "def aggregate_frequencies(reference_freqs, pop_map):\n",
        "    \"\"\"\n",
        "    Aggregates frequencies from fine-grained ethnicities into major population groups.\n",
        "    \"\"\"\n",
        "    major_pop_freqs = {}\n",
        "    major_populations = sorted(list(set(pop_map.values())))\n",
        "\n",
        "    # Initialize structure\n",
        "    for pop in major_populations:\n",
        "        major_pop_freqs[pop] = {}\n",
        "\n",
        "    variants = list(reference_freqs.keys())\n",
        "    for variant in variants:\n",
        "        # Temporary storage for averaging\n",
        "        pop_sums = {pop: 0.0 for pop in major_populations}\n",
        "        pop_counts = {pop: 0 for pop in major_populations}\n",
        "\n",
        "        for ethnicity, freq in reference_freqs[variant].items():\n",
        "            if ethnicity in pop_map:\n",
        "                major_pop = pop_map[ethnicity]\n",
        "                pop_sums[major_pop] += freq\n",
        "                pop_counts[major_pop] += 1\n",
        "\n",
        "        # Calculate average frequency for each major population\n",
        "        for pop in major_populations:\n",
        "            if pop_counts[pop] > 0:\n",
        "                major_pop_freqs[pop][variant] = pop_sums[pop] / pop_counts[pop]\n",
        "            else:\n",
        "                # If no ethnicities in the ref file map to this major pop, we can't calculate\n",
        "                major_pop_freqs[pop][variant] = None\n",
        "\n",
        "    return major_pop_freqs\n",
        "\n",
        "\n",
        "def calculate_admixture(sample_genotypes, major_pop_freqs):\n",
        "    \"\"\"\n",
        "    Calculates admixture proportions using a log-likelihood approach.\n",
        "    \"\"\"\n",
        "    log_likelihoods = {}\n",
        "    epsilon = 1e-9  # A small number to avoid log(0)\n",
        "\n",
        "    for pop, freqs in major_pop_freqs.items():\n",
        "        total_log_likelihood = 0.0\n",
        "        # Iterate over variants present in the sample\n",
        "        for variant, genotype in sample_genotypes.items():\n",
        "            if variant not in freqs or freqs[variant] is None:\n",
        "                continue # Skip variants not in the reference panel\n",
        "\n",
        "            p = freqs[variant]\n",
        "            p = max(epsilon, min(1 - epsilon, p)) # Clamp frequency to avoid math errors\n",
        "\n",
        "            # Hardy-Weinberg Equilibrium probabilities\n",
        "            if genotype == 0:  # Homozygous reference (e.g., A/A)\n",
        "                prob = (1 - p)**2\n",
        "            elif genotype == 1:  # Heterozygous (e.g., A/G)\n",
        "                prob = 2 * p * (1 - p)\n",
        "            else:  # Homozygous alternate (e.g., G/G)\n",
        "                prob = p**2\n",
        "\n",
        "            total_log_likelihood += math.log(max(prob, epsilon))\n",
        "\n",
        "        log_likelihoods[pop] = total_log_likelihood\n",
        "\n",
        "    # Normalize log-likelihoods to get proportions\n",
        "    # Subtracting the max log-likelihood before exponentiating is a standard numerical stability trick\n",
        "    max_log_like = max(log_likelihoods.values())\n",
        "    likelihoods = {pop: math.exp(ll - max_log_like) for pop, ll in log_likelihoods.items()}\n",
        "\n",
        "    total_likelihood = sum(likelihoods.values())\n",
        "    if total_likelihood == 0:\n",
        "        return {pop: 0.0 for pop in major_pop_freqs}\n",
        "\n",
        "    proportions = {pop: (like / total_likelihood) for pop, like in likelihoods.items()}\n",
        "\n",
        "    return proportions\n",
        "\n",
        "\n",
        "# --- VISUALIZATION ---\n",
        "\n",
        "def display_results(proportions):\n",
        "    \"\"\"\n",
        "    Displays the admixture results as a text-based stacked bar chart with a legend.\n",
        "    \"\"\"\n",
        "    # ANSI escape codes for background colors\n",
        "    colors = [41, 42, 43, 44, 45, 46, 47, 101, 102, 104]\n",
        "    reset_color = \"\\\\033[0m\"\n",
        "    bar_width = 100 # Total characters for the bar\n",
        "\n",
        "    print(\"\\\\n## Ancestry Composition Estimate ##\\\\n\")\n",
        "\n",
        "    # Sort proportions for consistent ordering\n",
        "    sorted_proportions = sorted(proportions.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # 1. Draw the stacked bar\n",
        "    sys.stdout.write(\"Total Composition: [\")\n",
        "    cumulative_width = 0\n",
        "    for i, (pop, perc) in enumerate(sorted_proportions):\n",
        "        if perc == 0: continue\n",
        "        color_code = colors[i % len(colors)]\n",
        "\n",
        "        # Calculate number of blocks for this segment\n",
        "        segment_width = round(perc * bar_width)\n",
        "\n",
        "        # Adjust last segment to fill the bar exactly to bar_width\n",
        "        if i == len([p for p in sorted_proportions if p[1] > 0]) - 1:\n",
        "            segment_width = bar_width - cumulative_width\n",
        "\n",
        "        sys.stdout.write(f\"\\\\033[{color_code}m{' ' * segment_width}\")\n",
        "        cumulative_width += segment_width\n",
        "\n",
        "    sys.stdout.write(f\"{reset_color}]\\\\n\\\\n\")\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    # 2. Draw the legend\n",
        "    print(\"Ancestry Breakdown:\")\n",
        "    for i, (pop, perc) in enumerate(sorted_proportions):\n",
        "        if perc == 0: continue\n",
        "        color_code = colors[i % len(colors)]\n",
        "        percentage_str = f\"{perc*100:.2f}%\"\n",
        "        # Use a block character (U+2588) or a simple space for the color key\n",
        "        block = \"█\"\n",
        "        print(f\"  \\\\033[{color_code}m{block}{reset_color} {pop:<22} {percentage_str:>8}\")\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting admixture analysis...\")\n",
        "\n",
        "    # 1. Parse input data\n",
        "    # In a real script, you'd use:\n",
        "    # with open('sample.vcf', 'r') as f: vcf_content = f.read()\n",
        "    # with open('reference.tsv', 'r') as f: tsv_content = f.read()\n",
        "    sample_genotypes = parse_vcf(sample_vcf_data)\n",
        "    reference_frequencies = parse_reference(reference_tsv_data)\n",
        "\n",
        "    print(f\"Parsed {len(sample_genotypes)} variants for the sample.\")\n",
        "    print(f\"Parsed {len(reference_frequencies)} variants from the reference panel.\")\n",
        "\n",
        "    # 2. Aggregate reference frequencies into major population groups\n",
        "    major_pop_frequencies = aggregate_frequencies(reference_frequencies, POPULATION_MAP)\n",
        "\n",
        "    # 3. Calculate admixture\n",
        "    admixture_proportions = calculate_admixture(sample_genotypes, major_pop_frequencies)\n",
        "\n",
        "    # 4. Display the results\n",
        "    if not any(admixture_proportions.values()):\n",
        "        print(\"\\\\nError: Could not calculate admixture. Check if variants in VCF match the reference.\")\n",
        "    else:\n",
        "        display_results(admixture_proportions)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "WE8XgPFAx26A"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}